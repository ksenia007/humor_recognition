{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meanGrade</th>\n",
       "      <th>score_std</th>\n",
       "      <th>basic_score</th>\n",
       "      <th>scaled_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump cites fake boob to make the case that su...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.687184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Louisiana school district : All students must ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green receives standing ovation at ‘ The Colo...</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Judge Orders State Department To Provide Withh...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATT Loses Another 1.36 Million Pay TV Subscrib...</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  meanGrade  score_std  \\\n",
       "0  Trump cites fake boob to make the case that su...   1.166667   0.687184   \n",
       "1  Louisiana school district : All students must ...   1.000000   0.632456   \n",
       "2   Green receives standing ovation at ‘ The Colo...   1.600000   1.200000   \n",
       "3  Judge Orders State Department To Provide Withh...   1.000000   0.632456   \n",
       "4  ATT Loses Another 1.36 Million Pay TV Subscrib...   1.400000   0.800000   \n",
       "\n",
       "   basic_score  scaled_mean  \n",
       "0          0.0     0.388889  \n",
       "1          0.0     0.333333  \n",
       "2          1.0     0.533333  \n",
       "3          0.0     0.333333  \n",
       "4          0.0     0.466667  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/created_datasets/humicroedit_unpaired_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21990, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trump cites fake boob to make the case that support for impeachment is falling'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = data.loc[0].text\n",
    "sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model and try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e27ca550fbe45d8944e550ddf88052f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pretrained_for_sentence(sent, len_sent = 25):\n",
    "    tokens = tokenizer.tokenize(sent)\n",
    "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "    padded_tokens = tokens + ['[PAD]' for _ in range(len_sent - len(tokens))]\n",
    "    attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "    sent_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    \n",
    "    #Step 5: Get BERT vocabulary index for each token\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "    #Converting everything to torch tensors before feeding them to bert_model\n",
    "    token_ids = torch.tensor(token_ids).unsqueeze(0) \n",
    "    attn_mask = torch.tensor(attn_mask).unsqueeze(0) \n",
    "    #Feed them to bert\n",
    "    hidden_reps, cls_head = bert_model(token_ids, attention_mask = attn_mask)\n",
    "    \n",
    "    return hidden_reps, cls_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.5 ms ± 5.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_pretrained_for_sentence(\"Test this function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actually training model\n",
    "\n",
    "Note: a lot borrowed from https://medium.com/swlh/painless-fine-tuning-of-bert-in-pytorch-b91c14912caa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meanGrade</th>\n",
       "      <th>score_std</th>\n",
       "      <th>basic_score</th>\n",
       "      <th>scaled_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump cites fake boob to make the case that su...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.687184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Louisiana school district : All students must ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green receives standing ovation at ‘ The Colo...</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Judge Orders State Department To Provide Withh...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATT Loses Another 1.36 Million Pay TV Subscrib...</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  meanGrade  score_std  \\\n",
       "0  Trump cites fake boob to make the case that su...   1.166667   0.687184   \n",
       "1  Louisiana school district : All students must ...   1.000000   0.632456   \n",
       "2   Green receives standing ovation at ‘ The Colo...   1.600000   1.200000   \n",
       "3  Judge Orders State Department To Provide Withh...   1.000000   0.632456   \n",
       "4  ATT Loses Another 1.36 Million Pay TV Subscrib...   1.400000   0.800000   \n",
       "\n",
       "   basic_score  scaled_mean  \n",
       "0          0.0     0.388889  \n",
       "1          0.0     0.333333  \n",
       "2          1.0     0.533333  \n",
       "3          0.0     0.333333  \n",
       "4          0.0     0.466667  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filename, maxlen):\n",
    "        self.df = pd.read_csv(filename)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') #Initialize the BERT tokenizer\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #Selecting the sentence and label at the specified index in the data frame\n",
    "        sentence = self.df.loc[index, 'text']\n",
    "        label = self.df.loc[index, 'scaled_mean']\n",
    "        \n",
    "        #Preprocessing the text to be suitable for BERT\n",
    "        #Tokenize the sentence\n",
    "        tokens_orig = self.tokenizer.tokenize(sentence) \n",
    "        \n",
    "        tokens = ['[CLS]'] + tokens_orig + ['[SEP]']\n",
    "        \n",
    "        if len(tokens) < self.maxlen:\n",
    "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
    "        else:\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
    "\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
    "\n",
    "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
    "        attn_mask = (tokens_ids_tensor != 0).long()\n",
    "\n",
    "        return tokens_ids_tensor, attn_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating instances of training and validation set\n",
    "train_set = HumorDataset(filename = 'data/created_datasets/humicroedit_unpaired_train.csv', maxlen = 30)\n",
    "val_set = HumorDataset(filename = 'data/created_datasets/humicroedit_unpaired_valid.csv', maxlen = 30)\n",
    "#Creating intsances of training and validation dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size = 64)\n",
    "val_loader = DataLoader(val_set, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  101,  8398, 17248,  8275, 22017,  2497,  2000,  2191,  1996,  2553,\n",
      "         2008,  2490,  2005, 17727,  5243, 22729,  2003,  4634,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0]), 0.3888888888888889)\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "class HumorRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, freeze_bert = True):\n",
    "        super(HumorRegressor, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        #Freeze bert layers\n",
    "        if freeze_bert:\n",
    "            for p in self.bert_layer.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        #Regression layer\n",
    "        self.fc1 = nn.Linear(768, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, seq, attn_masks):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
    "\n",
    "        #Obtaining the representation of [CLS] head\n",
    "        out = cont_reps[:, 0]\n",
    "        \n",
    "        #Feeding cls_rep to the regressor layer\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        #preds = self.cls_layer(cls_rep)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HumorRegressor(freeze_bert = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of epoch 1 complete. Loss : 0.2788054645061493\n",
      "Iteration 10 of epoch 1 complete. Loss : 0.2783444821834564\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0d498a0ec28b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#Obtaining the logits from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#Computing loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/!Summer2019/DeepSea_Disease/deepsea-disease/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a88329789e6f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq, attn_masks)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#Feeding the input to BERT model to obtain contextualized representations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mcont_reps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#Obtaining the representation of [CLS] head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/!Summer2019/DeepSea_Disease/deepsea-disease/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/!Summer2019/DeepSea_Disease/deepsea-disease/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         )\n\u001b[1;32m    801\u001b[0m         encoder_outputs = self.encoder(\n",
      "\u001b[0;32m~/Documents/!Summer2019/DeepSea_Disease/deepsea-disease/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ep in range(2):\n",
    "    loss_cum=0\n",
    "    for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
    "        #Clear gradients\n",
    "        opti.zero_grad()  \n",
    "        #Converting these to cuda tensors\n",
    "        #seq, attn_masks, labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu)\n",
    "\n",
    "        #Obtaining the logits from the model\n",
    "        preds = net(seq, attn_masks)\n",
    "\n",
    "        #Computing loss\n",
    "        loss = criterion(preds.squeeze(-1), labels.float())\n",
    "        loss_cum += loss\n",
    "\n",
    "        #Backpropagating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        if (it + 1) % 5 == 0:\n",
    "            print(\"Iteration {} of epoch {} complete. Loss : {}\".format(it+1, ep+1, \n",
    "                                                                    loss_cum.item()))\n",
    "            loss_cum = 0\n",
    "    loss_val = 0\n",
    "    with torch.no_grad():\n",
    "        for it, (seq, attn_masks, labels) in enumerate(val_loader):\n",
    "            preds = net(seq, attn_masks)\n",
    "            loss = criterion(preds.squeeze(-1), labels.float())\n",
    "            loss_val += loss\n",
    "            if (it + 1) % 10 == 0: print('Iteration ', it)\n",
    "        print('MSE on validaiton: ', loss_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val = 0\n",
    "with torch.no_grad():\n",
    "    for it, (seq, attn_masks, labels) in enumerate(val_loader):\n",
    "        preds = net(seq, attn_masks)\n",
    "        loss = criterion(preds.squeeze(-1), labels.float())\n",
    "        loss_val += loss\n",
    "        if (it + 1) % 10 == 0: print('Iteration ', it)\n",
    "print('MSE on validaiton: ', loss_val)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at examples from the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>edit</th>\n",
       "      <th>grades</th>\n",
       "      <th>meanGrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000</td>\n",
       "      <td>3986</td>\n",
       "      <td>Trump Replacing Secretary of &lt;State/&gt; Tillerso...</td>\n",
       "      <td>Class</td>\n",
       "      <td>11000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6001</td>\n",
       "      <td>9504</td>\n",
       "      <td>When George W. Bush &lt;stood/&gt; with Hillary Clinton</td>\n",
       "      <td>knitted</td>\n",
       "      <td>11111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6002</td>\n",
       "      <td>13642</td>\n",
       "      <td>South Korea &lt;hospital/&gt; fire : dozens feared d...</td>\n",
       "      <td>camp</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6003</td>\n",
       "      <td>9371</td>\n",
       "      <td>&lt;Trump/&gt; predicts Patriots will win Super Bow...</td>\n",
       "      <td>gypsy</td>\n",
       "      <td>33200</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6004</td>\n",
       "      <td>2947</td>\n",
       "      <td>Sessions announces new conditions for sanctuar...</td>\n",
       "      <td>launder</td>\n",
       "      <td>33210</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     id                                           original  \\\n",
       "0        6000   3986  Trump Replacing Secretary of <State/> Tillerso...   \n",
       "1        6001   9504  When George W. Bush <stood/> with Hillary Clinton   \n",
       "2        6002  13642  South Korea <hospital/> fire : dozens feared d...   \n",
       "3        6003   9371   <Trump/> predicts Patriots will win Super Bow...   \n",
       "4        6004   2947  Sessions announces new conditions for sanctuar...   \n",
       "\n",
       "      edit  grades  meanGrade  \n",
       "0    Class   11000        0.4  \n",
       "1  knitted   11111        1.0  \n",
       "2     camp   21000        0.6  \n",
       "3    gypsy   33200        1.6  \n",
       "4  launder   33210        1.8  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data = pd.read_csv('data/task-1/val_split.csv')\n",
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_for_sentence(sentence, replacement, maxlen):\n",
    "    sentence_change = replace_word(sentence, replacement)\n",
    "    sentence = drop_replacement_symbols(sentence)\n",
    "\n",
    "    #Preprocessing the text to be suitable for BERT\n",
    "    tokens_orig = tokenizer.tokenize(sentence) #Tokenize the sentence\n",
    "    tokens_new = tokenizer.tokenize(sentence_change)\n",
    "    tokens = ['[CLS]'] + tokens_orig + ['[SEP]'] + tokens_new + ['[SEP]'] \n",
    "    if len(tokens) < maxlen:\n",
    "        tokens = tokens + ['[PAD]' for _ in range(maxlen - len(tokens))] #Padding sentences\n",
    "    else:\n",
    "        tokens = tokens[:maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
    "\n",
    "    tokens_ids = tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
    "    tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
    "\n",
    "    #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
    "    attn_mask = (tokens_ids_tensor != 0).long()\n",
    "\n",
    "    return tokens_ids_tensor, attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Trump Replacing Secretary of <State/> Tillerson With CIA Director Mike Pompeo : NPR\n",
      "Alternative:  Trump Replacing Secretary of Class Tillerson With CIA Director Mike Pompeo : NPR\n",
      "Prediction is  tensor(0.8303)  True value:  0.4\n",
      "Sentence:  When George W. Bush <stood/> with Hillary Clinton\n",
      "Alternative:  When George W. Bush knitted with Hillary Clinton\n",
      "Prediction is  tensor(1.1504)  True value:  1.0\n",
      "Sentence:  South Korea <hospital/> fire : dozens feared dead and many injured\n",
      "Alternative:  South Korea camp fire : dozens feared dead and many injured\n",
      "Prediction is  tensor(0.7940)  True value:  0.6\n",
      "Sentence:   <Trump/> predicts Patriots will win Super Bowl by 8 points\n",
      "Alternative:   gypsy predicts Patriots will win Super Bowl by 8 points\n",
      "Prediction is  tensor(0.8824)  True value:  1.6\n",
      "Sentence:  Sessions announces new conditions for sanctuary cities to <get/> federal money\n",
      "Alternative:  Sessions announces new conditions for sanctuary cities to launder federal money\n",
      "Prediction is  tensor(1.2976)  True value:  1.8\n",
      "Sentence:  Trump to <unveil/> punishing trade actions against China Thursday\n",
      "Alternative:  Trump to cancel punishing trade actions against China Thursday\n",
      "Prediction is  tensor(0.9215)  True value:  0.6\n",
      "Sentence:  FBI nominee says Trump-Russia <probe/> is no ' witch hunt '\n",
      "Alternative:  FBI nominee says Trump-Russia infatuation is no ' witch hunt '\n",
      "Prediction is  tensor(1.0354)  True value:  0.6\n",
      "Sentence:  Former Trump <campaign/> adviser : Info given to Russian spies ' immaterial '\n",
      "Alternative:  Former Trump sandwich adviser : Info given to Russian spies ' immaterial '\n",
      "Prediction is  tensor(1.1732)  True value:  0.8\n",
      "Sentence:  NRA ’s Wayne LaPierre instructs CPAC to “ be frightened ” of “ <socialist/> wave ” following Parkland\n",
      "Alternative:  NRA ’s Wayne LaPierre instructs CPAC to “ be frightened ” of “ tidal wave ” following Parkland\n",
      "Prediction is  tensor(0.2724)  True value:  1.0\n",
      "Sentence:  Catholic priest caught driving 13-year-old girl to motel after paying 16-year-old <pimp/> \n",
      "Alternative:  Catholic priest caught driving 13-year-old girl to motel after paying 16-year-old cat \n",
      "Prediction is  tensor(1.1587)  True value:  1.2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    (ids, attn) = run_for_sentence(valid_data.loc[i].original, valid_data.loc[i].edit, maxlen=50)\n",
    "    with torch.no_grad():\n",
    "        pred = net(ids.unsqueeze(0), attn.unsqueeze(0))\n",
    "    print('Sentence: ', valid_data.loc[i].original)\n",
    "    print('Alternative: ', replace_word(valid_data.loc[i].original, valid_data.loc[i].edit))\n",
    "    print('Prediction is ', pred[0][0]*3, ' True value: ', valid_data.loc[i].meanGrade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_perf(data_loader):\n",
    "    loss_val = 0\n",
    "    preds_all = np.zeros(1)\n",
    "    truth_all = np.zeros(1)\n",
    "    with torch.no_grad():\n",
    "        for it, (seq, attn_masks, labels) in enumerate(data_loader):\n",
    "            preds = net(seq, attn_masks)\n",
    "            preds_all = np.append(preds_all, preds)\n",
    "            truth_all = np.append(truth_all, labels)\n",
    "            loss = criterion(preds.squeeze(-1), labels.float())\n",
    "            loss_val += loss\n",
    "            if (it + 1) % 10 == 0: \n",
    "                print('Iteration ', it)\n",
    "    truth_all = truth_all[1:]\n",
    "    preds_all = preds_all[1:]\n",
    "    print('MSE on validation: ', loss_val/(it+1))\n",
    "    print('RMSE on validation: ', np.sqrt(loss_val/(it+1)))\n",
    "    return truth_all, preds_all, np.sqrt(loss_val/(it+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  9\n",
      "Iteration  19\n",
      "Iteration  29\n",
      "Iteration  39\n",
      "Iteration  49\n",
      "MSE on validation:  tensor(0.0456)\n",
      "RMSE on validation:  tensor(0.2135)\n"
     ]
    }
   ],
   "source": [
    "truth_all, preds_all, rmse = holdout_perf(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.032532520220471046, pvalue=0.04931647291657385)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spearmanr(truth_all, preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predictions')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(truth_all*3, preds_all*3)\n",
    "plt.title('Preditions vs true labels')\n",
    "plt.xlabel('Truth')\n",
    "plt.ylabel('Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try predicting [MASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, c = run_pretrained_for_sentence('This is a [MASK] sentences', len_sent = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.8467e-01, -1.5410e-01,  4.5676e-01, -2.6751e-01, -3.5279e-01,\n",
       "         1.6615e-01, -4.5834e-03,  1.0484e-01, -3.8521e-01,  1.4572e-01,\n",
       "        -3.9893e-01, -6.4346e-02, -5.1810e-01, -8.5108e-02,  4.5921e-01,\n",
       "        -1.2399e-01,  9.1444e-02, -2.4186e-01,  1.1553e-01, -2.4419e-01,\n",
       "         4.1332e-01,  5.0311e-01, -1.0818e-01, -4.9766e-01,  4.6253e-01,\n",
       "         2.1118e-01,  1.7978e-01, -3.3571e-01, -2.3409e-01,  2.6158e-01,\n",
       "        -2.4863e-01, -4.7928e-02,  1.0342e-01,  1.3792e-01, -3.0125e-01,\n",
       "        -2.4333e-01, -3.8122e-01, -5.7470e-02, -8.6543e-02, -1.2808e-02,\n",
       "         8.1096e-02, -2.9649e-01, -1.5015e-01, -1.8059e-01, -2.8193e-01,\n",
       "         2.8478e-01, -4.3849e-01,  1.9499e-01, -2.1680e-01, -1.0943e-01,\n",
       "        -4.6547e-01,  2.4702e-02,  6.0991e-01,  3.7529e-01, -2.8480e-01,\n",
       "         3.5469e-01, -1.9837e-01, -3.7996e-01,  1.5978e-01, -3.3056e-01,\n",
       "         5.6390e-02,  2.3558e-01,  4.0455e-01,  3.9021e-01,  9.8947e-03,\n",
       "         2.4133e-01, -6.7638e-02,  6.3117e-02, -8.1921e-01,  1.2811e-01,\n",
       "        -2.9170e-01,  1.5302e-01,  7.9566e-02,  1.5956e-01,  6.6623e-02,\n",
       "         1.0228e-01,  1.5997e-02,  1.7587e-01,  5.6642e-02, -4.1086e-01,\n",
       "        -5.2132e-01,  2.0691e-01,  2.0517e-01, -8.9892e-02,  5.7324e-01,\n",
       "        -2.0825e-01, -4.4963e-02, -2.8210e-02, -4.1334e-01,  3.0562e-01,\n",
       "         4.7946e-01, -2.2304e-01, -2.5733e-01, -3.9837e-01,  2.1965e-01,\n",
       "        -5.2327e-02,  6.5727e-02,  4.7236e-02,  6.9344e-01,  1.3937e-01,\n",
       "        -7.7618e-02, -1.9736e-01, -8.7582e-02, -2.2790e-01,  6.7848e-02,\n",
       "        -2.7469e-01, -4.0875e-03,  9.9152e-02,  2.8802e-01, -3.6781e-03,\n",
       "         5.9064e-02,  1.2344e-01,  3.7852e-02,  2.3010e-01, -2.2095e-01,\n",
       "         3.1540e-01, -1.6557e-01,  1.7800e-01,  7.0619e-02, -2.4744e-01,\n",
       "        -3.7684e-01,  3.6024e-01,  1.8680e-01,  5.1718e-01,  2.3613e-01,\n",
       "        -9.4499e-02, -5.2542e-02, -8.0870e-02,  2.0127e-01, -4.9734e-01,\n",
       "         6.7735e-02,  2.5236e-01,  5.8153e-01,  3.9717e-02, -3.1799e-02,\n",
       "        -6.8025e-01, -4.3472e-01, -2.4985e-01, -5.7193e-01,  1.0802e-01,\n",
       "         2.1824e-01, -1.0365e-01,  3.7057e-01, -2.1492e-01,  4.1474e-01,\n",
       "        -1.2164e-01, -2.1919e-01,  8.6368e-02,  9.6264e-02,  2.0823e-02,\n",
       "         7.1496e-02,  5.7151e-01,  1.3853e-02, -3.4771e-01,  5.3001e-02,\n",
       "         1.8610e-01,  2.1438e-01, -3.8414e-02, -4.7333e-01, -6.8076e-02,\n",
       "         3.5001e-01,  9.3381e-01,  1.1482e-01,  1.0477e-01,  9.0537e-02,\n",
       "        -4.4331e-01,  1.5357e-01,  2.8533e-01, -4.8646e-01, -1.7823e-01,\n",
       "        -1.9547e-01, -3.1734e-01,  6.0335e-03, -2.2135e-01, -6.1548e-01,\n",
       "         1.8145e-01, -2.5317e-02, -8.7142e-02,  4.8720e-01, -5.6179e-01,\n",
       "        -1.0264e-01, -1.3042e-01, -2.4330e-01, -8.3371e-02,  6.2947e-02,\n",
       "         1.2396e-02,  3.1334e-01, -6.3525e-01,  1.4140e-01, -3.1786e-01,\n",
       "         1.7057e-01,  1.1091e-01,  8.9091e-02, -3.1890e-01,  2.9958e-01,\n",
       "         1.2892e-01, -3.0024e-01, -8.6126e-02,  1.8011e-01, -3.5608e-02,\n",
       "        -1.4477e-01,  1.2172e-01,  1.1297e-01, -6.8023e-02, -2.8717e-01,\n",
       "         3.4251e-01, -9.3557e-02,  9.6370e-02, -1.2235e-01,  3.2851e-01,\n",
       "        -3.0569e-02,  5.8570e-01,  5.0473e-01,  4.9353e-02,  1.2779e-01,\n",
       "        -3.4588e-01,  2.0362e-01, -4.0997e-01,  4.1976e-01,  1.1083e-01,\n",
       "         4.7235e-01,  2.4965e-01, -2.8798e-02, -4.8014e-03, -4.5241e-01,\n",
       "         3.1763e-01,  3.7953e-01,  3.2224e-01,  4.2939e-01, -4.9633e-02,\n",
       "        -1.5415e-01, -5.0974e-01,  5.1624e-03,  2.7455e-01,  6.0603e-02,\n",
       "         3.8059e-01,  1.8794e-01,  3.8927e-01, -3.2552e-01, -1.9411e-01,\n",
       "         5.9289e-02,  1.0046e-01, -3.4662e-01, -4.3919e-01, -2.8753e-01,\n",
       "        -1.8319e-01,  3.4603e-01, -3.6973e-01,  1.7458e-01, -2.9128e-01,\n",
       "        -1.9308e-01,  2.8058e-01, -2.5003e-01, -1.0113e-01, -4.5675e-01,\n",
       "         1.1117e-01, -2.0759e-01, -2.8172e-01,  3.4985e-01,  2.7996e-01,\n",
       "        -2.0703e-01,  2.2098e-01,  1.7048e-01, -3.6123e-01, -4.4869e-01,\n",
       "         2.1020e-01, -1.9411e-01,  4.2344e-01,  4.2528e-01,  3.2813e-01,\n",
       "        -8.3602e-02, -5.9124e-01, -1.0970e-01,  2.4118e-01,  2.8092e-01,\n",
       "        -5.8170e-02, -1.7815e-02,  1.0312e-01, -4.5030e-01,  1.3595e-01,\n",
       "        -1.5461e-01, -4.0590e-02,  2.7882e-01, -2.7698e-01, -2.2637e-02,\n",
       "        -6.0681e-01,  9.5428e-02,  9.5941e-02, -2.3466e-01, -1.9899e-02,\n",
       "        -4.5501e-01,  2.7677e-01, -2.6925e-01, -2.4529e-01,  4.0560e-01,\n",
       "        -2.4844e-01,  2.6643e-01, -3.0669e-02, -1.6544e-01,  3.5459e-02,\n",
       "        -1.4510e-01, -2.6096e-01, -2.5383e-01, -1.6586e-01, -8.2935e-02,\n",
       "         1.4242e-01,  1.4101e-01,  3.6246e-01, -6.6201e+00, -4.0052e-02,\n",
       "        -2.5922e-01, -2.9565e-01,  1.0393e-02,  1.4760e-01, -2.7207e-01,\n",
       "        -3.4226e-02, -1.7031e-01,  1.6662e-01, -2.3933e-01, -4.9083e-01,\n",
       "        -4.9549e-01,  3.5126e-01,  1.0348e-01, -6.9753e-02, -3.4363e-01,\n",
       "         1.1979e-01,  1.9035e-01,  1.8741e-01, -7.9643e-02,  7.9437e-02,\n",
       "        -4.7447e-02, -4.3683e-01,  1.4246e-02,  2.4253e-01, -1.2363e-01,\n",
       "         3.6048e-01, -3.4908e-01, -2.9637e-01, -6.1210e-02, -1.8355e-01,\n",
       "        -1.3510e-02,  1.0548e-01,  6.2115e-02,  8.1430e-02,  4.2010e-01,\n",
       "        -1.3099e-01,  2.1615e-01,  2.3341e-01, -1.4153e-01,  2.4316e-02,\n",
       "        -1.2701e-01, -1.9979e-01,  3.4732e-01,  2.7524e-02, -9.0205e-04,\n",
       "         2.8998e-02, -1.3054e-01, -1.3954e-02, -2.1534e-01,  2.6694e-03,\n",
       "         2.3914e-01, -7.1217e-03,  2.5516e-01, -2.2227e-02,  1.6496e-01,\n",
       "         1.5177e-01,  3.9284e-02, -8.1374e-02,  5.0926e-01, -6.6957e-02,\n",
       "         8.4023e-02, -2.1219e-01, -1.7435e-01,  2.0273e-01, -7.4222e-01,\n",
       "        -1.6981e-01,  1.2510e-01,  9.5989e-02, -4.6736e-01, -2.5465e-01,\n",
       "        -2.7346e-02, -1.5533e-01, -4.7162e-02, -1.6644e-01,  1.2000e-01,\n",
       "         9.5166e-04,  1.2538e-01, -9.8260e-02, -1.6143e-01, -4.4405e-01,\n",
       "        -1.0531e-01,  2.5518e-01,  2.8150e-01, -2.7032e-01, -4.7759e-01,\n",
       "         8.7665e-03, -2.7816e-01,  2.8553e-01,  5.4468e-01,  3.6017e-02,\n",
       "        -9.9363e-02, -9.5831e-02, -3.9805e-02,  3.5276e-01,  3.2300e-01,\n",
       "         5.7865e-02,  4.1722e-01, -4.4482e-02,  5.0711e-01, -4.2205e-01,\n",
       "        -1.0969e-01,  7.3051e-02, -1.4801e-03,  3.0072e-01, -7.5458e-01,\n",
       "         8.9156e-02,  1.8781e-01, -1.1407e-02,  4.2407e-01,  1.1339e-01,\n",
       "        -9.8836e-02, -2.6111e-01, -1.9504e-01,  2.8827e-01,  6.2460e-02,\n",
       "         2.5541e-01,  4.6465e-01,  1.0333e-01, -1.8726e-01,  1.9256e-01,\n",
       "        -2.5983e-01, -3.2805e-01, -6.0294e-01, -3.8358e-02, -6.7942e-02,\n",
       "        -5.3286e-02, -2.9617e-02, -1.7448e-01, -4.2935e-01,  4.9266e-01,\n",
       "         2.0945e-01, -1.4170e-01,  2.6589e-01, -2.6219e-01, -4.7048e-02,\n",
       "         7.5436e-01,  2.2829e-01, -2.3075e-01,  3.6367e-01,  7.7234e-03,\n",
       "        -1.9661e-01,  9.4648e-03, -1.0044e-01,  2.3369e-01, -1.3577e-01,\n",
       "        -1.7193e-01,  2.1479e-01,  1.4301e-02,  2.3085e-01, -4.9715e-01,\n",
       "         3.8251e-01, -1.7787e-01, -8.9751e-02, -3.6364e-01,  3.5611e-01,\n",
       "        -1.3505e-01,  1.7077e-01, -6.5243e-02,  8.8299e-02, -1.7423e-01,\n",
       "         7.4514e-03, -2.3170e-01, -1.9945e-01, -1.8760e-01, -2.1429e-01,\n",
       "         2.6224e-01, -2.9289e-01, -3.3671e-01, -3.2940e-01,  1.2873e-01,\n",
       "         2.8400e-02,  5.2167e-01,  2.9783e-01, -6.7625e-02,  1.0799e-01,\n",
       "         3.6514e-01,  1.8965e-01,  5.9650e-01, -2.7547e-03,  1.9631e-01,\n",
       "         2.1614e-01,  2.0511e-01, -1.1066e-01,  3.4496e-01, -1.1852e-01,\n",
       "        -6.2767e-02, -1.6098e-02, -5.4588e-02,  3.5274e-01,  3.6463e-02,\n",
       "         3.3726e-01, -9.5220e-02,  8.8376e-02, -2.8519e-01,  3.7758e-01,\n",
       "         6.2053e-01,  1.0575e-02,  9.9454e-03, -9.0625e-02,  4.1056e-01,\n",
       "        -1.4087e-01, -1.9654e-01,  4.8631e-01, -1.3727e-01, -4.6921e-02,\n",
       "         3.9069e-02, -3.3869e-01, -2.9076e-01,  1.6397e-01, -1.8372e-01,\n",
       "        -4.1260e-02, -5.4328e-01,  1.1829e-01, -1.1655e-01,  2.0882e-01,\n",
       "         2.7004e-01, -1.1082e-01, -4.4122e-01,  1.4638e-01, -3.3276e-01,\n",
       "         3.0955e-01,  2.1287e-01,  5.6537e-01, -5.2539e-02, -2.3932e-01,\n",
       "        -4.5258e-01,  2.7698e-01,  9.3542e-02, -2.5348e-01, -8.7204e-02,\n",
       "        -9.1744e-03, -1.7386e-01,  9.5760e-02, -5.7257e-01, -4.3576e-01,\n",
       "        -1.0480e-01,  4.3750e-02, -4.8344e-01,  6.1474e-02,  9.1401e-02,\n",
       "        -3.3353e-01, -2.3659e-01, -2.2773e-01, -4.4908e-02,  4.3587e-02,\n",
       "         5.7630e-02,  3.9242e-01,  4.0656e-01, -3.8265e-01,  4.7580e-01,\n",
       "        -2.1687e-01,  1.9383e-01,  2.9632e-01, -1.5743e-01,  4.7248e-03,\n",
       "        -5.4471e-01, -3.4291e-01,  3.3320e-01, -1.6507e-01,  6.5173e-01,\n",
       "        -5.7543e-02,  2.5146e-01,  3.4440e-01,  4.3663e-01,  9.7691e-02,\n",
       "         4.8238e-02,  2.9539e-01,  6.2624e-01, -5.8976e-01, -9.3641e-02,\n",
       "        -3.6928e-02,  5.6018e-01,  5.5750e-01,  1.0310e-01, -3.3207e-01,\n",
       "         2.6652e-01, -1.7921e-01,  2.6873e-01, -1.3888e-01, -3.0442e-01,\n",
       "        -2.6058e-01, -5.1282e-02,  3.2461e-01,  3.0906e-01, -2.9924e-01,\n",
       "        -2.4622e-01, -1.8430e-01,  6.6164e-02,  1.6038e-01,  5.8073e-01,\n",
       "        -9.9791e-02, -4.6135e-01, -1.7894e-01, -6.4105e-03,  2.2040e-01,\n",
       "         2.9228e-01,  8.1136e-02, -1.5833e-01,  1.4808e-01, -8.3338e-02,\n",
       "         5.6477e-02,  1.4264e-01, -1.7334e-02,  6.9113e-02, -8.1359e-02,\n",
       "         1.7578e-02, -1.4503e-01,  1.1807e-01, -2.4807e-01,  3.5526e-01,\n",
       "         1.7792e-01,  1.9131e-01,  1.2916e-01, -3.5172e-01,  1.2010e-01,\n",
       "        -1.8925e-01,  1.1750e-01,  1.8884e-01, -3.8912e-02, -4.0566e-01,\n",
       "         3.6275e-01, -2.6064e-01, -3.8800e-01,  9.9553e-02, -1.8112e-01,\n",
       "        -1.7289e-01,  9.3666e-02, -1.3049e-01,  5.2827e-01,  3.3103e-01,\n",
       "        -2.9667e-01,  2.5988e-01, -5.8122e-01, -2.1983e-02,  2.0682e-01,\n",
       "         2.4163e-01,  4.7577e-01, -4.2790e-01,  4.0827e-01,  2.9671e-01,\n",
       "        -9.7336e-02, -4.6457e-01, -4.1222e-01, -2.3620e-01,  7.2212e-02,\n",
       "        -2.4020e-01, -2.7920e-01,  7.0692e-01,  4.1601e-01,  3.9531e-02,\n",
       "         2.6784e-01,  9.1974e-02,  2.3191e-01,  1.0756e-01,  8.7110e-02,\n",
       "        -6.9591e-02, -5.2455e-02, -3.1576e-02,  2.0367e-01,  2.5158e-01,\n",
       "        -2.0741e-01,  4.2047e-01,  4.4408e-03, -3.0229e-02,  4.5803e-01,\n",
       "        -7.1561e-03, -1.5258e-01, -2.6479e-01, -2.7695e-01,  1.7414e-01,\n",
       "         1.1117e-01,  5.4275e-01, -1.3539e-01, -9.0342e-03, -1.4510e-02,\n",
       "        -6.1503e-02,  1.0598e-01,  1.0050e-01,  3.0342e-01,  3.3871e-02,\n",
       "         1.0402e-01,  9.3676e-02,  5.5440e-02,  4.2325e-03, -2.3873e-01,\n",
       "         9.8588e-02, -2.0499e-01, -1.7022e-01,  4.2963e-02, -1.2179e-01,\n",
       "        -4.5650e-01, -2.2448e-01,  7.0718e-01, -2.2017e-01, -1.8612e-01,\n",
       "         3.3296e-01,  6.9317e-01, -1.4495e-01,  1.2831e-01, -2.6766e-01,\n",
       "         2.2991e-01, -1.0892e-01,  2.6313e-01, -1.8489e-01, -1.5729e-01,\n",
       "         2.1261e-02, -1.2702e-01, -3.1363e-02,  2.9622e-01,  1.9684e-01,\n",
       "        -1.3680e-01,  3.5943e-01, -1.3348e-01, -1.1595e-01, -8.4196e-03,\n",
       "        -1.1610e-01,  2.1095e-01, -1.9559e-01, -5.1061e-01, -2.4525e-01,\n",
       "        -1.4954e-01,  3.3458e-01, -1.9453e-01,  9.6037e-02, -4.1474e-01,\n",
       "         6.5855e-02, -3.1952e-01,  9.3529e-02,  1.3226e-01, -4.5483e-02,\n",
       "        -9.5666e-02,  8.8883e-01, -3.6178e-02, -5.4247e-01,  1.5428e-02,\n",
       "         2.5120e-01,  2.1084e-02, -2.8711e-01, -6.2542e-01,  3.3950e-01,\n",
       "        -2.3181e-02,  2.3574e-01, -3.0044e-01, -7.6074e-02, -4.0411e-02,\n",
       "         7.5289e-02, -4.3369e-01,  4.7992e-02,  1.4139e-01,  4.1330e-01,\n",
       "        -6.0207e-02, -2.2339e-01, -3.0349e-01,  2.0228e-01,  5.1880e-01,\n",
       "        -7.5214e-02,  1.2757e-01,  1.7185e-01], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, c1 = run_pretrained_for_sentence('This is a test sentences', len_sent = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9222, grad_fn=<DistBackward>)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(h1[0][4], h[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2370, grad_fn=<DistBackward>)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dist(h1[0][5], h[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', '[MASK]']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103, 2572, 103]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[MASK] am [MASK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsea-disease",
   "language": "python",
   "name": "deepsea-disease"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
